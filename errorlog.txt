24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8398332343591260866,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.173.152:56766; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:123)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6205937397341054495,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.174.150:55508; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:51)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:111)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6471011352619188291,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8465136262299005141,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.174.150:55508; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:51)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:111)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7259792118668918117,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.173.152:56766; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:123)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=9034972206858279045,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.174.150:55508; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:51)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:111)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6184903665685727680,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=4843513299127259761,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.174.150:55508; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:51)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:111)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6211744581547090415,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.173.152:56766; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:123)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=4616152911429165931,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.174.150:55508; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:51)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:111)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7938215802635047816,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=5080449067050873587,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.173.152:56766; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:123)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7444706744182803142,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=9029295385934707353,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.173.152:56766; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:123)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=4621446760861247203,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.173.152:56766; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:123)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8237694063900346256,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.173.152:56766; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:123)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=5972586468418514771,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.174.150:55508; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:51)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:111)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6442535596690607285,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.173.152:56766; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:123)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=4843780760864731357,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=5841910544645120517,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.174.150:55508; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:51)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:111)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6063815400838301963,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7072046382571871032,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.173.152:56766; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:123)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6262206341208531489,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=5551131180489750289,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.173.152:56766; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:123)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6035087676184624249,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.173.152:56766; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:123)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7964024924267960720,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=5270103962529140762,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=47 cap=64]]] to /10.143.174.140:49464; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7611338848315387562,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.173.152:56766; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:148)
        at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:123)
        at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:362)
        at io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:238)
        at io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:212)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:400)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7830378168461859539,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=47 cap=64]]] to /10.143.174.140:49464; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7044996031521232348,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6944272539801321708,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6263161116963142356,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6748725215166144851,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8105603719358117936,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8095671214359258492,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=47 cap=64]]] to /10.143.174.140:49464; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=4842356271813311575,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=4772083233597678045,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8449599300598249246,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7044387647522149403,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6750456279914857159,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=5676388906358622068,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7901445666642857295,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8880331275388351671,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7439280587503687037,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6797863616535292969,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8151177748370372166,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8021987290931175463,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7861765424530161812,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=5631627919398163475,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7436308009558868309,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=5370578910687159739,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8137041628047613321,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6694981043096484132,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7979412894650862104,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=4788427760687393917,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=5048825633619822465,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=9012302749453469294,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcFailure[requestId=5899380442116114040,errorString=org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.
        at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)
        at org.apache.spark.rpc.netty.Dispatcher.postRemoteMessage(Dispatcher.scala:136)
        at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:683)
        at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)
        at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)
        at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)
        at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
        at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
] to /10.143.175.80:51840; closing connection
java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:51)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:408)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:790)
        at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:758)
        at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:808)
        at io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1025)
        at io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:306)
        at org.apache.spark.network.server.TransportRequestHandler.respond(TransportRequestHandler.java:312)
        at org.apache.spark.network.server.TransportRequestHandler.access$000(TransportRequestHandler.java:46)
        at org.apache.spark.network.server.TransportRequestHandler$1.onFailure(TransportRequestHandler.java:171)
        at org.apache.spark.rpc.netty.Dispatcher.$anonfun$postRemoteMessage$1(Dispatcher.scala:136)
        at org.apache.spark.rpc.netty.Dispatcher.$anonfun$postRemoteMessage$1$adapted(Dispatcher.scala:136)
        at scala.Option.foreach(Option.scala:407)
        at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:185)
        at org.apache.spark.rpc.netty.Dispatcher.postRemoteMessage(Dispatcher.scala:136)
        at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:683)
        at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)
        at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)
        at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)
        at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
        at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7607289814888363683,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=7779719481681188045,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6927585447219977651,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8186449847751530129,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=9093652347888136603,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcFailure[requestId=5485196725217162743,errorString=org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.
        at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)
        at org.apache.spark.rpc.netty.Dispatcher.postRemoteMessage(Dispatcher.scala:136)
        at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:683)
        at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)
        at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)
        at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)
        at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
        at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
] to /10.143.175.80:51840; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:51)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469)
        at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:408)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:949)
        at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
        at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:913)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
        at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
        at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
        at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
        at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:790)
        at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:758)
        at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:808)
        at io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1025)
        at io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:306)
        at org.apache.spark.network.server.TransportRequestHandler.respond(TransportRequestHandler.java:312)
        at org.apache.spark.network.server.TransportRequestHandler.access$000(TransportRequestHandler.java:46)
        at org.apache.spark.network.server.TransportRequestHandler$1.onFailure(TransportRequestHandler.java:171)
        at org.apache.spark.rpc.netty.Dispatcher.$anonfun$postRemoteMessage$1(Dispatcher.scala:136)
        at org.apache.spark.rpc.netty.Dispatcher.$anonfun$postRemoteMessage$1$adapted(Dispatcher.scala:136)
        at scala.Option.foreach(Option.scala:407)
        at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:185)
        at org.apache.spark.rpc.netty.Dispatcher.postRemoteMessage(Dispatcher.scala:136)
        at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:683)
        at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:163)
        at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)
        at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)
        at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
        at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8215621108544354090,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6224350073487226467,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6436108466688661813,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8737466505500955044,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8225117148853196862,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6134828376586215797,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8735761424309991205,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6014451930027069541,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=6929993040460252871,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
24/07/29 14:19:49 ERROR server.TransportRequestHandler: Error sending result RpcResponse[requestId=8172401010169962223,body=NioManagedBuffer[buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]]] to /10.143.165.203:53202; closing connection
io.netty.channel.StacklessClosedChannelException
        at io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)
ERROR:__main__:Error displaying Trunk Group Outgoing Join Results: An error occurred while calling o280.showString.
: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.lang.reflect.Constructor.newInstance(Constructor.java:423)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
py4j.ClientServerConnection.run(ClientServerConnection.java:106)
java.lang.Thread.run(Thread.java:748)

The currently active SparkContext was created at:

(No active SparkContext.)

        at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)
        at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1522)
        at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:102)
        at org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:131)
        at org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:122)
        at org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:177)
        at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:426)
        at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:417)
        at org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:504)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)
        at org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:526)
        at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:454)
        at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:453)
        at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:497)
        at org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)
        at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:750)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)
        at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:326)
        at org.apache.spark.sql.execution.SparkPlan.executeCollectIterator(SparkPlan.scala:417)
        at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.$anonfun$relationFuture$1(BroadcastExchangeExec.scala:137)
        at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$1(SQLExecution.scala:185)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)

INFO:__main__:Network Node Incoming Join Results:
ERROR:__main__:Error displaying Network Node Incoming Join Results: An error occurred while calling o287.showString.
: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.lang.reflect.Constructor.newInstance(Constructor.java:423)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
py4j.ClientServerConnection.run(ClientServerConnection.java:106)
java.lang.Thread.run(Thread.java:748)

The currently active SparkContext was created at:

(No active SparkContext.)

        at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)
        at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1522)
        at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:102)
        at org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:131)
        at org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:122)
        at org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:177)
        at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:426)
        at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:417)
        at org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:504)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)
        at org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:526)
        at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:454)
        at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:453)
        at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:497)
        at org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:237)
        at org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)
        at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:750)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD$lzycompute(ShuffleExchangeExec.scala:135)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD(ShuffleExchangeExec.scala:135)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture$lzycompute(ShuffleExchangeExec.scala:140)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture(ShuffleExchangeExec.scala:139)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.$anonfun$submitShuffleJob$1(ShuffleExchangeExec.scala:68)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob(ShuffleExchangeExec.scala:68)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob$(ShuffleExchangeExec.scala:67)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.submitShuffleJob(ShuffleExchangeExec.scala:115)
        at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture$lzycompute(QueryStageExec.scala:170)
        at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture(QueryStageExec.scala:170)
        at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.doMaterialize(QueryStageExec.scala:172)
        at org.apache.spark.sql.execution.adaptive.QueryStageExec.materialize(QueryStageExec.scala:82)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5(AdaptiveSparkPlanExec.scala:258)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5$adapted(AdaptiveSparkPlanExec.scala:256)
        at scala.collection.Iterator.foreach(Iterator.scala:943)
        at scala.collection.Iterator.foreach$(Iterator.scala:943)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
        at scala.collection.IterableLike.foreach(IterableLike.scala:74)
        at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$1(AdaptiveSparkPlanExec.scala:256)
        at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.getFinalPhysicalPlan(AdaptiveSparkPlanExec.scala:228)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:370)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:343)
        at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)
        at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)
        at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)
        at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
        at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
        at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
        at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
        at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
        at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)
        at org.apache.spark.sql.Dataset.head(Dataset.scala:2728)
        at org.apache.spark.sql.Dataset.take(Dataset.scala:2935)
        at org.apache.spark.sql.Dataset.getRows(Dataset.scala:287)
        at org.apache.spark.sql.Dataset.showString(Dataset.scala:326)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
        at py4j.Gateway.invoke(Gateway.java:282)
        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
        at py4j.commands.CallCommand.execute(CallCommand.java:79)
        at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
        at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
        at java.lang.Thread.run(Thread.java:748)

INFO:__main__:Network Node Outgoing Join Results:
ERROR:__main__:Error displaying Network Node Outgoing Join Results: An error occurred while calling o294.showString.
: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.lang.reflect.Constructor.newInstance(Constructor.java:423)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
py4j.ClientServerConnection.run(ClientServerConnection.java:106)
java.lang.Thread.run(Thread.java:748)

The currently active SparkContext was created at:

(No active SparkContext.)

        at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)
        at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1522)
        at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:102)
        at org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:131)
        at org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:122)
        at org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:177)
        at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:426)
        at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:417)
        at org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:504)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)
        at org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:526)
        at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:454)
        at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:453)
        at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:497)
        at org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:237)
        at org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)
        at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:750)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD$lzycompute(ShuffleExchangeExec.scala:135)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD(ShuffleExchangeExec.scala:135)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture$lzycompute(ShuffleExchangeExec.scala:140)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture(ShuffleExchangeExec.scala:139)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.$anonfun$submitShuffleJob$1(ShuffleExchangeExec.scala:68)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob(ShuffleExchangeExec.scala:68)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob$(ShuffleExchangeExec.scala:67)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.submitShuffleJob(ShuffleExchangeExec.scala:115)
        at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture$lzycompute(QueryStageExec.scala:170)
        at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture(QueryStageExec.scala:170)
        at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.doMaterialize(QueryStageExec.scala:172)
        at org.apache.spark.sql.execution.adaptive.QueryStageExec.materialize(QueryStageExec.scala:82)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5(AdaptiveSparkPlanExec.scala:258)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5$adapted(AdaptiveSparkPlanExec.scala:256)
        at scala.collection.Iterator.foreach(Iterator.scala:943)
        at scala.collection.Iterator.foreach$(Iterator.scala:943)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
        at scala.collection.IterableLike.foreach(IterableLike.scala:74)
        at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$1(AdaptiveSparkPlanExec.scala:256)
        at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.getFinalPhysicalPlan(AdaptiveSparkPlanExec.scala:228)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:370)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:343)
        at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)
        at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)
        at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)
        at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
        at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
        at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
        at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
        at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
        at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)
        at org.apache.spark.sql.Dataset.head(Dataset.scala:2728)
        at org.apache.spark.sql.Dataset.take(Dataset.scala:2935)
        at org.apache.spark.sql.Dataset.getRows(Dataset.scala:287)
        at org.apache.spark.sql.Dataset.showString(Dataset.scala:326)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
        at py4j.Gateway.invoke(Gateway.java:282)
        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
        at py4j.commands.CallCommand.execute(CallCommand.java:79)
        at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
        at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
        at java.lang.Thread.run(Thread.java:748)

INFO:__main__:Combined Enriched DataFrame:
24/07/29 14:19:50 ERROR adaptive.AdaptiveSparkPlanExec: Exception in cancelling query stage: ShuffleQueryStage 5
+- ReusedExchange [network_id#60, network_name#64, FK_ORGA_FRAN#1062], Exchange hashpartitioning(network_id#60, 200), ENSURE_REQUIREMENTS, [plan_id=693]

java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.lang.reflect.Constructor.newInstance(Constructor.java:423)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
py4j.ClientServerConnection.run(ClientServerConnection.java:106)
java.lang.Thread.run(Thread.java:748)

The currently active SparkContext was created at:

(No active SparkContext.)

        at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)
        at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1522)
        at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:102)
        at org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:131)
        at org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:122)
        at org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:177)
        at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:426)
        at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:417)
        at org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:504)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)
        at org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:526)
        at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:454)
        at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:453)
        at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:497)
        at org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:237)
        at org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)
        at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:750)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD$lzycompute(ShuffleExchangeExec.scala:135)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD(ShuffleExchangeExec.scala:135)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture$lzycompute(ShuffleExchangeExec.scala:140)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture(ShuffleExchangeExec.scala:139)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.$anonfun$submitShuffleJob$1(ShuffleExchangeExec.scala:68)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob(ShuffleExchangeExec.scala:68)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob$(ShuffleExchangeExec.scala:67)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.submitShuffleJob(ShuffleExchangeExec.scala:115)
        at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture$lzycompute(QueryStageExec.scala:170)
        at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture(QueryStageExec.scala:170)
        at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.cancel(QueryStageExec.scala:183)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$cleanUpAndThrowException$1(AdaptiveSparkPlanExec.scala:733)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$cleanUpAndThrowException$1$adapted(AdaptiveSparkPlanExec.scala:728)
        at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:253)
        at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreach$1(TreeNode.scala:254)
        at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreach$1$adapted(TreeNode.scala:254)
        at scala.collection.Iterator.foreach(Iterator.scala:943)
        at scala.collection.Iterator.foreach$(Iterator.scala:943)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
        at scala.collection.IterableLike.foreach(IterableLike.scala:74)
        at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
        at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:254)
        at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreach$1(TreeNode.scala:254)
        at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreach$1$adapted(TreeNode.scala:254)
        at scala.collection.Iterator.foreach(Iterator.scala:943)
        at scala.collection.Iterator.foreach$(Iterator.scala:943)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
        at scala.collection.IterableLike.foreach(IterableLike.scala:74)
        at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
        at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:254)
        at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreach$1(TreeNode.scala:254)
        at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreach$1$adapted(TreeNode.scala:254)
        at scala.collection.Iterator.foreach(Iterator.scala:943)
        at scala.collection.Iterator.foreach$(Iterator.scala:943)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
        at scala.collection.IterableLike.foreach(IterableLike.scala:74)
        at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
        at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:254)
        at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreach$1(TreeNode.scala:254)
        at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreach$1$adapted(TreeNode.scala:254)
        at scala.collection.Iterator.foreach(Iterator.scala:943)
        at scala.collection.Iterator.foreach$(Iterator.scala:943)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
        at scala.collection.IterableLike.foreach(IterableLike.scala:74)
        at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
        at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:254)
        at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreach$1(TreeNode.scala:254)
        at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreach$1$adapted(TreeNode.scala:254)
        at scala.collection.Iterator.foreach(Iterator.scala:943)
        at scala.collection.Iterator.foreach$(Iterator.scala:943)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
        at scala.collection.IterableLike.foreach(IterableLike.scala:74)
        at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
        at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:254)
        at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreach$1(TreeNode.scala:254)
        at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreach$1$adapted(TreeNode.scala:254)
        at scala.collection.Iterator.foreach(Iterator.scala:943)
        at scala.collection.Iterator.foreach$(Iterator.scala:943)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
        at scala.collection.IterableLike.foreach(IterableLike.scala:74)
        at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
        at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:254)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.cleanUpAndThrowException(AdaptiveSparkPlanExec.scala:728)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5(AdaptiveSparkPlanExec.scala:267)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5$adapted(AdaptiveSparkPlanExec.scala:256)
        at scala.collection.Iterator.foreach(Iterator.scala:943)
        at scala.collection.Iterator.foreach$(Iterator.scala:943)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
        at scala.collection.IterableLike.foreach(IterableLike.scala:74)
        at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$1(AdaptiveSparkPlanExec.scala:256)
        at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.getFinalPhysicalPlan(AdaptiveSparkPlanExec.scala:228)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:370)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:343)
        at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)
        at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)
        at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)
        at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
        at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
        at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
        at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
        at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
        at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)
        at org.apache.spark.sql.Dataset.head(Dataset.scala:2728)
        at org.apache.spark.sql.Dataset.take(Dataset.scala:2935)
        at org.apache.spark.sql.Dataset.getRows(Dataset.scala:287)
        at org.apache.spark.sql.Dataset.showString(Dataset.scala:326)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
        at py4j.Gateway.invoke(Gateway.java:282)
        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
        at py4j.commands.CallCommand.execute(CallCommand.java:79)
        at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
        at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
        at java.lang.Thread.run(Thread.java:748)
ERROR:__main__:Error displaying Combined Enriched DataFrame: An error occurred while calling o366.showString.
: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.lang.reflect.Constructor.newInstance(Constructor.java:423)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
py4j.ClientServerConnection.run(ClientServerConnection.java:106)
java.lang.Thread.run(Thread.java:748)

The currently active SparkContext was created at:

(No active SparkContext.)

        at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)
        at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1522)
        at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:102)
        at org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:131)
        at org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:122)
        at org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:177)
        at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:426)
        at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:417)
        at org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:504)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)
        at org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:526)
        at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:454)
        at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:453)
        at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:497)
        at org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:237)
        at org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)
        at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:750)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD$lzycompute(ShuffleExchangeExec.scala:135)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD(ShuffleExchangeExec.scala:135)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture$lzycompute(ShuffleExchangeExec.scala:140)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture(ShuffleExchangeExec.scala:139)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.$anonfun$submitShuffleJob$1(ShuffleExchangeExec.scala:68)
        at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob(ShuffleExchangeExec.scala:68)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob$(ShuffleExchangeExec.scala:67)
        at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.submitShuffleJob(ShuffleExchangeExec.scala:115)
        at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture$lzycompute(QueryStageExec.scala:170)
        at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture(QueryStageExec.scala:170)
        at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.doMaterialize(QueryStageExec.scala:172)
        at org.apache.spark.sql.execution.adaptive.QueryStageExec.materialize(QueryStageExec.scala:82)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5(AdaptiveSparkPlanExec.scala:258)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5$adapted(AdaptiveSparkPlanExec.scala:256)
        at scala.collection.Iterator.foreach(Iterator.scala:943)
        at scala.collection.Iterator.foreach$(Iterator.scala:943)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
        at scala.collection.IterableLike.foreach(IterableLike.scala:74)
        at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$1(AdaptiveSparkPlanExec.scala:256)
        at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.getFinalPhysicalPlan(AdaptiveSparkPlanExec.scala:228)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:370)
        at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:343)
        at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)
        at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)
        at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)
        at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
        at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
        at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
        at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
        at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
        at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)
        at org.apache.spark.sql.Dataset.head(Dataset.scala:2728)
        at org.apache.spark.sql.Dataset.take(Dataset.scala:2935)
        at org.apache.spark.sql.Dataset.getRows(Dataset.scala:287)
        at org.apache.spark.sql.Dataset.showString(Dataset.scala:326)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
        at py4j.Gateway.invoke(Gateway.java:282)
        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
        at py4j.commands.CallCommand.execute(CallCommand.java:79)
        at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
        at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
        at java.lang.Thread.run(Thread.java:748)

Traceback (most recent call last):
  File "<stdin>", line 222, in <module>
  File "<stdin>", line 187, in apply_field_mapping
  File "/usr/local/lib/python3.6/site-packages/pyspark/sql/dataframe.py", line 2478, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sql_ctx)
  File "/usr/local/lib/python3.6/site-packages/pyspark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1322, in __call__
  File "/usr/local/lib/python3.6/site-packages/pyspark/sql/utils.py", line 117, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: cannot resolve 'incoming_POI' given input columns: [EVENT_DIRECTION, enriched_df_trunk_incoming.FK_NNOD, network_node_master_df.FK_ORGA_FRAN, enriched_df_trunk_incoming.OPERATOR, enriched_df_trunk_incoming.POI, enriched_df_trunk_incoming.anum, enriched_df_trunk_incoming.bnum, enriched_df_trunk_incoming.data_unit, enriched_df_trunk_incoming.discrete_rating_parameter_1, enriched_df_trunk_incoming.event_duration, enriched_df_trunk_incoming.event_start_date, enriched_df_trunk_incoming.event_start_time, enriched_df_trunk_incoming.filename, enriched_df_trunk_incoming.incoming_node, enriched_df_trunk_incoming.incoming_path, enriched_df_trunk_incoming.incoming_product, enriched_df_trunk_incoming.link_field, network_node_master_df.network_id, network_node_master_df.network_name, enriched_df_trunk_incoming.original_date, enriched_df_trunk_incoming.outgoing_node, enriched_df_trunk_incoming.outgoing_path, enriched_df_trunk_incoming.outgoing_product, enriched_df_trunk_incoming.processing_date, enriched_df_trunk_incoming.record_sequence_number, enriched_df_trunk_incoming.record_type, enriched_df_trunk_incoming.trunk_id, enriched_df_trunk_incoming.trunk_name, enriched_df_trunk_incoming.user_data, enriched_df_trunk_incoming.user_data_2, enriched_df_trunk_incoming.user_data_3, enriched_df_trunk_incoming.user_summarisation];
'Project [filename#70, incoming_node#73, outgoing_node#491, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, EVENT_DIRECTION#1791, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391, processing_date#540, ... 9 more fields]
+- Project [filename#70, incoming_node#73, outgoing_node#491, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, CASE WHEN NOT (incoming_path#122 = ) THEN I WHEN NOT (outgoing_path#133 = ) THEN O ELSE T END AS EVENT_DIRECTION#1791, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391, processing_date#540, ... 8 more fields]
   +- Union false, false
      :- Project [filename#70, incoming_node#73, outgoing_node#491, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391, processing_date#540, ... 8 more fields]
      :  +- Join LeftOuter, (incoming_node#73 = network_id#60)
      :     :- SubqueryAlias enriched_df_trunk_incoming
      :     :  +- Join LeftOuter, ((incoming_path#122 = trunk_id#26) OR (incoming_node#73 = FK_NNOD#18))
      :     :     :- SubqueryAlias processed_df
      :     :     :  +- Project [filename#70, incoming_node#73, outgoing_node#491, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391, current_date(Some(Asia/Kolkata)) AS processing_date#540]
      :     :     :     +- Project [filename#70, incoming_node#73, outgoing_node#491, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391]
      :     :     :        +- Union false, false
      :     :     :           :- Project [value#68, filename#70, incoming_node#73, cast(outgoing_node#416 as string) AS outgoing_node#491, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391]
      :     :     :           :  +- Project [value#68, filename#70, incoming_node#73, null AS outgoing_node#416, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391]
      :     :     :           :     +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, regexp_extract(filename#70, \d{8}, 0) AS original_date#391]
      :     :     :           :        +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, to_date('event_start_date, Some(yyyyMMdd)) AS event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343]
      :     :     :           :           +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, CASE WHEN (substring(value#68, 339, 80) <=> ) THEN NULL ELSE substring(value#68, 339, 80) END AS user_data_3#343]
      :     :     :           :              +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, CASE WHEN (substring(value#68, 337, 2) <=> ) THEN NULL ELSE substring(value#68, 337, 2) END AS link_field#320]
      :     :     :           :                 +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, CASE WHEN (substring(value#68, 307, 30) <=> ) THEN NULL ELSE substring(value#68, 307, 30) END AS user_data_2#298]
      :     :     :           :                    +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, CASE WHEN (substring(value#68, 277, 30) <=> ) THEN NULL ELSE substring(value#68, 277, 30) END AS user_data#277]
      :     :     :           :                       +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, CASE WHEN (substring(value#68, 257, 20) <=> ) THEN NULL ELSE substring(value#68, 257, 20) END AS user_summarisation#257]
      :     :     :           :                          +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, CASE WHEN (substring(value#68, 255, 2) <=> ) THEN NULL ELSE substring(value#68, 255, 2) END AS record_type#238]
      :     :     :           :                             +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, CASE WHEN (substring(value#68, 215, 40) <=> ) THEN NULL ELSE substring(value#68, 215, 40) END AS record_sequence_number#220]
      :     :     :           :                                +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, CASE WHEN (substring(value#68, 207, 8) <=> ) THEN NULL ELSE substring(value#68, 207, 8) END AS data_unit#203]
      :     :     :           :                                   +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, CASE WHEN (substring(value#68, 192, 15) <=> ) THEN NULL ELSE substring(value#68, 192, 15) END AS discrete_rating_parameter_1#187]
      :     :     :           :                                      +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, CASE WHEN (substring(value#68, 191, 1) <=> ) THEN NULL ELSE substring(value#68, 191, 1) END AS event_direction#172]
      :     :     :           :                                         +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, CASE WHEN (substring(value#68, 177, 14) <=> ) THEN NULL ELSE substring(value#68, 177, 14) END AS outgoing_product#158]
      :     :     :           :                                            +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, CASE WHEN (substring(value#68, 163, 14) <=> ) THEN NULL ELSE substring(value#68, 163, 14) END AS incoming_product#145]
      :     :     :           :                                               +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, CASE WHEN (substring(value#68, 143, 20) <=> ) THEN NULL ELSE substring(value#68, 143, 20) END AS outgoing_path#133]
      :     :     :           :                                                  +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, CASE WHEN (substring(value#68, 123, 20) <=> ) THEN NULL ELSE substring(value#68, 123, 20) END AS incoming_path#122]
      :     :     :           :                                                     +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, CASE WHEN (substring(value#68, 95, 28) <=> ) THEN NULL ELSE substring(value#68, 95, 28) END AS bnum#112]
      :     :     :           :                                                        +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, CASE WHEN (substring(value#68, 67, 28) <=> ) THEN NULL ELSE substring(value#68, 67, 28) END AS anum#103]
      :     :     :           :                                                           +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, CASE WHEN (substring(value#68, 57, 10) <=> ) THEN NULL ELSE substring(value#68, 57, 10) END AS event_duration#95]
      :     :     :           :                                                              +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, CASE WHEN (substring(value#68, 49, 8) <=> ) THEN NULL ELSE substring(value#68, 49, 8) END AS event_start_time#88]
      :     :     :           :                                                                 +- Project [value#68, filename#70, incoming_node#73, outgoing_node#77, CASE WHEN (substring(value#68, 41, 8) <=> ) THEN NULL ELSE substring(value#68, 41, 8) END AS event_start_date#82]
      :     :     :           :                                                                    +- Project [value#68, filename#70, incoming_node#73, CASE WHEN (substring(value#68, 21, 20) <=> ) THEN NULL ELSE substring(value#68, 21, 20) END AS outgoing_node#77]
      :     :     :           :                                                                       +- Project [value#68, filename#70, CASE WHEN (substring(value#68, 1, 20) <=> ) THEN NULL ELSE substring(value#68, 1, 20) END AS incoming_node#73]
      :     :     :           :                                                                          +- Project [value#68, input_file_name() AS filename#70]
      :     :     :           :                                                                             +- Relation [value#68] text
      :     :     :           +- Project [value#467, filename#468, cast(incoming_node#469 as string) AS incoming_node#492, outgoing_node#470, event_start_date#471, event_start_time#472, event_duration#473, anum#474, bnum#475, incoming_path#476, outgoing_path#477, incoming_product#478, outgoing_product#479, event_direction#480, discrete_rating_parameter_1#481, data_unit#482, record_sequence_number#483, record_type#484, user_summarisation#485, user_data#486, user_data_2#487, link_field#488, user_data_3#489, original_date#490]
      :     :     :              +- Project [value#466 AS value#467, filename#70 AS filename#468, incoming_node#441 AS incoming_node#469, outgoing_node#77 AS outgoing_node#470, event_start_date#367 AS event_start_date#471, event_start_time#88 AS event_start_time#472, event_duration#95 AS event_duration#473, anum#103 AS anum#474, bnum#112 AS bnum#475, incoming_path#122 AS incoming_path#476, outgoing_path#133 AS outgoing_path#477, incoming_product#145 AS incoming_product#478, outgoing_product#158 AS outgoing_product#479, event_direction#172 AS event_direction#480, discrete_rating_parameter_1#187 AS discrete_rating_parameter_1#481, data_unit#203 AS data_unit#482, record_sequence_number#220 AS record_sequence_number#483, record_type#238 AS record_type#484, user_summarisation#257 AS user_summarisation#485, user_data#277 AS user_data#486, user_data_2#298 AS user_data_2#487, link_field#320 AS link_field#488, user_data_3#343 AS user_data_3#489, original_date#391 AS original_date#490]
      :     :     :                 +- Project [value#466, filename#70, null AS incoming_node#441, outgoing_node#77, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391]
      :     :     :                    +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, regexp_extract(filename#70, \d{8}, 0) AS original_date#391]
      :     :     :                       +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, to_date('event_start_date, Some(yyyyMMdd)) AS event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343]
      :     :     :                          +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, CASE WHEN (substring(value#466, 339, 80) <=> ) THEN NULL ELSE substring(value#466, 339, 80) END AS user_data_3#343]
      :     :     :                             +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, CASE WHEN (substring(value#466, 337, 2) <=> ) THEN NULL ELSE substring(value#466, 337, 2) END AS link_field#320]
      :     :     :                                +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, CASE WHEN (substring(value#466, 307, 30) <=> ) THEN NULL ELSE substring(value#466, 307, 30) END AS user_data_2#298]
      :     :     :                                   +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, CASE WHEN (substring(value#466, 277, 30) <=> ) THEN NULL ELSE substring(value#466, 277, 30) END AS user_data#277]
      :     :     :                                      +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, CASE WHEN (substring(value#466, 257, 20) <=> ) THEN NULL ELSE substring(value#466, 257, 20) END AS user_summarisation#257]
      :     :     :                                         +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, CASE WHEN (substring(value#466, 255, 2) <=> ) THEN NULL ELSE substring(value#466, 255, 2) END AS record_type#238]
      :     :     :                                            +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, CASE WHEN (substring(value#466, 215, 40) <=> ) THEN NULL ELSE substring(value#466, 215, 40) END AS record_sequence_number#220]
      :     :     :                                               +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, CASE WHEN (substring(value#466, 207, 8) <=> ) THEN NULL ELSE substring(value#466, 207, 8) END AS data_unit#203]
      :     :     :                                                  +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, CASE WHEN (substring(value#466, 192, 15) <=> ) THEN NULL ELSE substring(value#466, 192, 15) END AS discrete_rating_parameter_1#187]
      :     :     :                                                     +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, CASE WHEN (substring(value#466, 191, 1) <=> ) THEN NULL ELSE substring(value#466, 191, 1) END AS event_direction#172]
      :     :     :                                                        +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, CASE WHEN (substring(value#466, 177, 14) <=> ) THEN NULL ELSE substring(value#466, 177, 14) END AS outgoing_product#158]
      :     :     :                                                           +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, CASE WHEN (substring(value#466, 163, 14) <=> ) THEN NULL ELSE substring(value#466, 163, 14) END AS incoming_product#145]
      :     :     :                                                              +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, CASE WHEN (substring(value#466, 143, 20) <=> ) THEN NULL ELSE substring(value#466, 143, 20) END AS outgoing_path#133]
      :     :     :                                                                 +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, CASE WHEN (substring(value#466, 123, 20) <=> ) THEN NULL ELSE substring(value#466, 123, 20) END AS incoming_path#122]
      :     :     :                                                                    +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, CASE WHEN (substring(value#466, 95, 28) <=> ) THEN NULL ELSE substring(value#466, 95, 28) END AS bnum#112]
      :     :     :                                                                       +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, CASE WHEN (substring(value#466, 67, 28) <=> ) THEN NULL ELSE substring(value#466, 67, 28) END AS anum#103]
      :     :     :                                                                          +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, CASE WHEN (substring(value#466, 57, 10) <=> ) THEN NULL ELSE substring(value#466, 57, 10) END AS event_duration#95]
      :     :     :                                                                             +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, CASE WHEN (substring(value#466, 49, 8) <=> ) THEN NULL ELSE substring(value#466, 49, 8) END AS event_start_time#88]
      :     :     :                                                                                +- Project [value#466, filename#70, incoming_node#73, outgoing_node#77, CASE WHEN (substring(value#466, 41, 8) <=> ) THEN NULL ELSE substring(value#466, 41, 8) END AS event_start_date#82]
      :     :     :                                                                                   +- Project [value#466, filename#70, incoming_node#73, CASE WHEN (substring(value#466, 21, 20) <=> ) THEN NULL ELSE substring(value#466, 21, 20) END AS outgoing_node#77]
      :     :     :                                                                                      +- Project [value#466, filename#70, CASE WHEN (substring(value#466, 1, 20) <=> ) THEN NULL ELSE substring(value#466, 1, 20) END AS incoming_node#73]
      :     :     :                                                                                         +- Project [value#466, input_file_name() AS filename#70]
      :     :     :                                                                                            +- Relation [value#466] text
      :     :     +- SubqueryAlias trunk_group_master_df
      :     :        +- Project [trunk_id#26, NAME#17 AS trunk_name#32, FK_NNOD#18, OPERATOR#19, POI#20]
      :     :           +- Project [ID#16 AS trunk_id#26, NAME#17, FK_NNOD#18, OPERATOR#19, POI#20]
      :     :              +- SubqueryAlias trunk_group_master_df
      :     :                 +- Relation [ID#16,NAME#17,FK_NNOD#18,OPERATOR#19,POI#20] csv
      :     +- SubqueryAlias network_node_master_df
      :        +- Project [network_id#60, NAME#55 AS network_name#64, FK_ORGA_FRAN#56]
      :           +- Project [ID#54 AS network_id#60, NAME#55, FK_ORGA_FRAN#56]
      :              +- SubqueryAlias network_node_master_df
      :                 +- Relation [ID#54,NAME#55,FK_ORGA_FRAN#56] csv
      +- Project [filename#70 AS filename#1063, incoming_node#73 AS incoming_node#1064, outgoing_node#491 AS outgoing_node#1065, event_start_date#367 AS event_start_date#1066, event_start_time#88 AS event_start_time#1067, event_duration#95 AS event_duration#1068, anum#103 AS anum#1069, bnum#112 AS bnum#1070, incoming_path#122 AS incoming_path#1071, outgoing_path#133 AS outgoing_path#1072, incoming_product#145 AS incoming_product#1073, outgoing_product#158 AS outgoing_product#1074, event_direction#172 AS event_direction#1075, discrete_rating_parameter_1#187 AS discrete_rating_parameter_1#1076, data_unit#203 AS data_unit#1077, record_sequence_number#220 AS record_sequence_number#1078, record_type#238 AS record_type#1079, user_summarisation#257 AS user_summarisation#1080, user_data#277 AS user_data#1081, user_data_2#298 AS user_data_2#1082, link_field#320 AS link_field#1083, user_data_3#343 AS user_data_3#1084, original_date#391 AS original_date#1085, processing_date#540 AS processing_date#1086, ... 8 more fields]
         +- Project [filename#70, incoming_node#73, outgoing_node#491, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391, processing_date#540, ... 8 more fields]
            +- Project [filename#70, incoming_node#73, outgoing_node#491, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391, processing_date#540, ... 8 more fields]
               +- Join LeftOuter, (outgoing_node#491 = network_id#60)
                  :- SubqueryAlias enriched_df_trunk_outgoing
                  :  +- Join LeftOuter, ((outgoing_path#133 = trunk_id#26) OR (outgoing_node#491 = FK_NNOD#1057))
                  :     :- SubqueryAlias processed_df
                  :     :  +- Project [filename#70, incoming_node#73, outgoing_node#491, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391, current_date(Some(Asia/Kolkata)) AS processing_date#540]
                  :     :     +- Project [filename#70, incoming_node#73, outgoing_node#491, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391]
                  :     :        +- Union false, false
                  :     :           :- Project [value#1053, filename#70, incoming_node#73, cast(outgoing_node#416 as string) AS outgoing_node#491, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391]
                  :     :           :  +- Project [value#1053, filename#70, incoming_node#73, null AS outgoing_node#416, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391]
                  :     :           :     +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, regexp_extract(filename#70, \d{8}, 0) AS original_date#391]
                  :     :           :        +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, to_date('event_start_date, Some(yyyyMMdd)) AS event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343]
                  :     :           :           +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, CASE WHEN (substring(value#1053, 339, 80) <=> ) THEN NULL ELSE substring(value#1053, 339, 80) END AS user_data_3#343]
                  :     :           :              +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, CASE WHEN (substring(value#1053, 337, 2) <=> ) THEN NULL ELSE substring(value#1053, 337, 2) END AS link_field#320]
                  :     :           :                 +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, CASE WHEN (substring(value#1053, 307, 30) <=> ) THEN NULL ELSE substring(value#1053, 307, 30) END AS user_data_2#298]
                  :     :           :                    +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, CASE WHEN (substring(value#1053, 277, 30) <=> ) THEN NULL ELSE substring(value#1053, 277, 30) END AS user_data#277]
                  :     :           :                       +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, CASE WHEN (substring(value#1053, 257, 20) <=> ) THEN NULL ELSE substring(value#1053, 257, 20) END AS user_summarisation#257]
                  :     :           :                          +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, CASE WHEN (substring(value#1053, 255, 2) <=> ) THEN NULL ELSE substring(value#1053, 255, 2) END AS record_type#238]
                  :     :           :                             +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, CASE WHEN (substring(value#1053, 215, 40) <=> ) THEN NULL ELSE substring(value#1053, 215, 40) END AS record_sequence_number#220]
                  :     :           :                                +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, CASE WHEN (substring(value#1053, 207, 8) <=> ) THEN NULL ELSE substring(value#1053, 207, 8) END AS data_unit#203]
                  :     :           :                                   +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, CASE WHEN (substring(value#1053, 192, 15) <=> ) THEN NULL ELSE substring(value#1053, 192, 15) END AS discrete_rating_parameter_1#187]
                  :     :           :                                      +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, CASE WHEN (substring(value#1053, 191, 1) <=> ) THEN NULL ELSE substring(value#1053, 191, 1) END AS event_direction#172]
                  :     :           :                                         +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, CASE WHEN (substring(value#1053, 177, 14) <=> ) THEN NULL ELSE substring(value#1053, 177, 14) END AS outgoing_product#158]
                  :     :           :                                            +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, CASE WHEN (substring(value#1053, 163, 14) <=> ) THEN NULL ELSE substring(value#1053, 163, 14) END AS incoming_product#145]
                  :     :           :                                               +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, CASE WHEN (substring(value#1053, 143, 20) <=> ) THEN NULL ELSE substring(value#1053, 143, 20) END AS outgoing_path#133]
                  :     :           :                                                  +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, CASE WHEN (substring(value#1053, 123, 20) <=> ) THEN NULL ELSE substring(value#1053, 123, 20) END AS incoming_path#122]
                  :     :           :                                                     +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, CASE WHEN (substring(value#1053, 95, 28) <=> ) THEN NULL ELSE substring(value#1053, 95, 28) END AS bnum#112]
                  :     :           :                                                        +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, CASE WHEN (substring(value#1053, 67, 28) <=> ) THEN NULL ELSE substring(value#1053, 67, 28) END AS anum#103]
                  :     :           :                                                           +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, CASE WHEN (substring(value#1053, 57, 10) <=> ) THEN NULL ELSE substring(value#1053, 57, 10) END AS event_duration#95]
                  :     :           :                                                              +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, CASE WHEN (substring(value#1053, 49, 8) <=> ) THEN NULL ELSE substring(value#1053, 49, 8) END AS event_start_time#88]
                  :     :           :                                                                 +- Project [value#1053, filename#70, incoming_node#73, outgoing_node#77, CASE WHEN (substring(value#1053, 41, 8) <=> ) THEN NULL ELSE substring(value#1053, 41, 8) END AS event_start_date#82]
                  :     :           :                                                                    +- Project [value#1053, filename#70, incoming_node#73, CASE WHEN (substring(value#1053, 21, 20) <=> ) THEN NULL ELSE substring(value#1053, 21, 20) END AS outgoing_node#77]
                  :     :           :                                                                       +- Project [value#1053, filename#70, CASE WHEN (substring(value#1053, 1, 20) <=> ) THEN NULL ELSE substring(value#1053, 1, 20) END AS incoming_node#73]
                  :     :           :                                                                          +- Project [value#1053, input_file_name() AS filename#70]
                  :     :           :                                                                             +- Relation [value#1053] text
                  :     :           +- Project [value#467, filename#468, cast(incoming_node#469 as string) AS incoming_node#492, outgoing_node#470, event_start_date#471, event_start_time#472, event_duration#473, anum#474, bnum#475, incoming_path#476, outgoing_path#477, incoming_product#478, outgoing_product#479, event_direction#480, discrete_rating_parameter_1#481, data_unit#482, record_sequence_number#483, record_type#484, user_summarisation#485, user_data#486, user_data_2#487, link_field#488, user_data_3#489, original_date#490]
                  :     :              +- Project [value#1054 AS value#467, filename#70 AS filename#468, incoming_node#441 AS incoming_node#469, outgoing_node#77 AS outgoing_node#470, event_start_date#367 AS event_start_date#471, event_start_time#88 AS event_start_time#472, event_duration#95 AS event_duration#473, anum#103 AS anum#474, bnum#112 AS bnum#475, incoming_path#122 AS incoming_path#476, outgoing_path#133 AS outgoing_path#477, incoming_product#145 AS incoming_product#478, outgoing_product#158 AS outgoing_product#479, event_direction#172 AS event_direction#480, discrete_rating_parameter_1#187 AS discrete_rating_parameter_1#481, data_unit#203 AS data_unit#482, record_sequence_number#220 AS record_sequence_number#483, record_type#238 AS record_type#484, user_summarisation#257 AS user_summarisation#485, user_data#277 AS user_data#486, user_data_2#298 AS user_data_2#487, link_field#320 AS link_field#488, user_data_3#343 AS user_data_3#489, original_date#391 AS original_date#490]
                  :     :                 +- Project [value#1054, filename#70, null AS incoming_node#441, outgoing_node#77, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, original_date#391]
                  :     :                    +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343, regexp_extract(filename#70, \d{8}, 0) AS original_date#391]
                  :     :                       +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, to_date('event_start_date, Some(yyyyMMdd)) AS event_start_date#367, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, user_data_3#343]
                  :     :                          +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, link_field#320, CASE WHEN (substring(value#1054, 339, 80) <=> ) THEN NULL ELSE substring(value#1054, 339, 80) END AS user_data_3#343]
                  :     :                             +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, user_data_2#298, CASE WHEN (substring(value#1054, 337, 2) <=> ) THEN NULL ELSE substring(value#1054, 337, 2) END AS link_field#320]
                  :     :                                +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, user_data#277, CASE WHEN (substring(value#1054, 307, 30) <=> ) THEN NULL ELSE substring(value#1054, 307, 30) END AS user_data_2#298]
                  :     :                                   +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, user_summarisation#257, CASE WHEN (substring(value#1054, 277, 30) <=> ) THEN NULL ELSE substring(value#1054, 277, 30) END AS user_data#277]
                  :     :                                      +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, record_type#238, CASE WHEN (substring(value#1054, 257, 20) <=> ) THEN NULL ELSE substring(value#1054, 257, 20) END AS user_summarisation#257]
                  :     :                                         +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, record_sequence_number#220, CASE WHEN (substring(value#1054, 255, 2) <=> ) THEN NULL ELSE substring(value#1054, 255, 2) END AS record_type#238]
                  :     :                                            +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, data_unit#203, CASE WHEN (substring(value#1054, 215, 40) <=> ) THEN NULL ELSE substring(value#1054, 215, 40) END AS record_sequence_number#220]
                  :     :                                               +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, discrete_rating_parameter_1#187, CASE WHEN (substring(value#1054, 207, 8) <=> ) THEN NULL ELSE substring(value#1054, 207, 8) END AS data_unit#203]
                  :     :                                                  +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, event_direction#172, CASE WHEN (substring(value#1054, 192, 15) <=> ) THEN NULL ELSE substring(value#1054, 192, 15) END AS discrete_rating_parameter_1#187]
                  :     :                                                     +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, outgoing_product#158, CASE WHEN (substring(value#1054, 191, 1) <=> ) THEN NULL ELSE substring(value#1054, 191, 1) END AS event_direction#172]
                  :     :                                                        +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, incoming_product#145, CASE WHEN (substring(value#1054, 177, 14) <=> ) THEN NULL ELSE substring(value#1054, 177, 14) END AS outgoing_product#158]
                  :     :                                                           +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, outgoing_path#133, CASE WHEN (substring(value#1054, 163, 14) <=> ) THEN NULL ELSE substring(value#1054, 163, 14) END AS incoming_product#145]
                  :     :                                                              +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, incoming_path#122, CASE WHEN (substring(value#1054, 143, 20) <=> ) THEN NULL ELSE substring(value#1054, 143, 20) END AS outgoing_path#133]
                  :     :                                                                 +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, bnum#112, CASE WHEN (substring(value#1054, 123, 20) <=> ) THEN NULL ELSE substring(value#1054, 123, 20) END AS incoming_path#122]
                  :     :                                                                    +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, anum#103, CASE WHEN (substring(value#1054, 95, 28) <=> ) THEN NULL ELSE substring(value#1054, 95, 28) END AS bnum#112]
                  :     :                                                                       +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, event_duration#95, CASE WHEN (substring(value#1054, 67, 28) <=> ) THEN NULL ELSE substring(value#1054, 67, 28) END AS anum#103]
                  :     :                                                                          +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, event_start_time#88, CASE WHEN (substring(value#1054, 57, 10) <=> ) THEN NULL ELSE substring(value#1054, 57, 10) END AS event_duration#95]
                  :     :                                                                             +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, event_start_date#82, CASE WHEN (substring(value#1054, 49, 8) <=> ) THEN NULL ELSE substring(value#1054, 49, 8) END AS event_start_time#88]
                  :     :                                                                                +- Project [value#1054, filename#70, incoming_node#73, outgoing_node#77, CASE WHEN (substring(value#1054, 41, 8) <=> ) THEN NULL ELSE substring(value#1054, 41, 8) END AS event_start_date#82]
                  :     :                                                                                   +- Project [value#1054, filename#70, incoming_node#73, CASE WHEN (substring(value#1054, 21, 20) <=> ) THEN NULL ELSE substring(value#1054, 21, 20) END AS outgoing_node#77]
                  :     :                                                                                      +- Project [value#1054, filename#70, CASE WHEN (substring(value#1054, 1, 20) <=> ) THEN NULL ELSE substring(value#1054, 1, 20) END AS incoming_node#73]
                  :     :                                                                                         +- Project [value#1054, input_file_name() AS filename#70]
                  :     :                                                                                            +- Relation [value#1054] text
                  :     +- SubqueryAlias trunk_group_master_df
                  :        +- Project [trunk_id#26, NAME#1056 AS trunk_name#32, FK_NNOD#1057, OPERATOR#1058, POI#1059]
                  :           +- Project [ID#1055 AS trunk_id#26, NAME#1056, FK_NNOD#1057, OPERATOR#1058, POI#1059]
                  :              +- SubqueryAlias trunk_group_master_df
                  :                 +- Relation [ID#1055,NAME#1056,FK_NNOD#1057,OPERATOR#1058,POI#1059] csv
                  +- SubqueryAlias network_node_master_df
                     +- Project [network_id#60, NAME#1061 AS network_name#64, FK_ORGA_FRAN#1062]
                        +- Project [ID#1060 AS network_id#60, NAME#1061, FK_ORGA_FRAN#1062]
                           +- SubqueryAlias network_node_master_df
                              +- Relation [ID#1060,NAME#1061,FK_ORGA_FRAN#1062] csv